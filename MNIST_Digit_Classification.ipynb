{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN for MNIST Handwritten Digit Classification\n",
        "**Author:** Khai Ta  \n",
        "**Date:** October 2024\n",
        "\n",
        "In this project, I implement a Convolutional Neural Network (CNN) to classify handwritten digits from the MNIST dataset using PyTorch.\n",
        "\n"
      ],
      "metadata": {
        "id": "UYhapkxz48x0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Importing Libraries"
      ],
      "metadata": {
        "id": "wI7HNJEH9EmV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Pw5AIpt5gFC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Loading the MNIST Dataset\n",
        "\n",
        "We use the `torchvision` library to download and load the MNIST dataset, which consists of 28x28 grayscale images of handwritten digits (0-9). We create training and testing datasets and use `DataLoader` for batching."
      ],
      "metadata": {
        "id": "XKVteUX65INR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(root='data', train=True, transform=ToTensor(), download=True)\n",
        "test_data = datasets.MNIST(root='data', train=False, transform=ToTensor(), download=True)\n",
        "\n",
        "loaders = {\n",
        "    'train': DataLoader(train_data, batch_size=100, shuffle=True, num_workers=1),\n",
        "    'test': DataLoader(test_data, batch_size=100, shuffle=False, num_workers=1),\n",
        "}"
      ],
      "metadata": {
        "id": "x2DRVmar6USq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5e2554a-b614-4477-e1b8-16a2936656d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 179914452.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 62667198.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 87107392.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 11380244.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Defining the CNN Model\n",
        "\n",
        "We define a CNN model that includes two convolutional layers, dropout for regularization, and two fully connected layers for classification. The model uses ReLU activations and outputs log probabilities."
      ],
      "metadata": {
        "id": "5RhGHjDe5XBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "hmly4-Kl84-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Setting Up the Training Environment\n",
        "\n",
        "We check if a GPU is available for faster computations. We also define the optimizer (Adam) and the loss function (CrossEntropyLoss)."
      ],
      "metadata": {
        "id": "jmUl1OBS5k3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = CNN().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Jz2THQFQ9dr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Training the Model\n",
        "\n",
        "We implement a training loop where the model is trained for a specified number of epochs. During training, we print the loss every 50 batches to monitor progress."
      ],
      "metadata": {
        "id": "ADhVaXnM5svy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = loss_fn(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 50 == 0:\n",
        "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} '\n",
        "                  f'({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\tLoss: {loss.item():.6f}')"
      ],
      "metadata": {
        "id": "PSYqUWPxcczz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Testing the Model\n",
        "\n",
        "After training, we evaluate the model on the test dataset, calculating the average loss and accuracy."
      ],
      "metadata": {
        "id": "3XKCLQmT5-PH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in loaders['test']:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += loss_fn(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(loaders['test'])\n",
        "    accuracy = 100. * correct / len(loaders['test'].dataset)\n",
        "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} '\n",
        "          f'({accuracy:.0f}%)\\n')"
      ],
      "metadata": {
        "id": "76Ar_wvag_xv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Training and Evaluating the Model\n",
        "\n",
        "We train the model for 10 epochs and evaluate its performance on the test set after each epoch."
      ],
      "metadata": {
        "id": "CjtOUxMb6HtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 11):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTcjAWae6FG-",
        "outputId": "2cfb8f88-745e-4a4b-fa52-95d8c6077782"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.311407\n",
            "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 1.349567\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.926795\n",
            "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 0.558738\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.610995\n",
            "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 0.450791\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.452746\n",
            "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 0.454863\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.411161\n",
            "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 0.355754\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.354147\n",
            "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 0.412353\n",
            "\n",
            "Test set: Average loss: 0.1309, Accuracy: 9589/10000 (96%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.333234\n",
            "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 0.302078\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.322604\n",
            "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 0.425043\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.234575\n",
            "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 0.485616\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.338395\n",
            "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 0.265354\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.270101\n",
            "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 0.251616\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.302043\n",
            "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 0.264191\n",
            "\n",
            "Test set: Average loss: 0.0893, Accuracy: 9712/10000 (97%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.348293\n",
            "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 0.264156\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.263369\n",
            "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 0.255473\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.354559\n",
            "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 0.162819\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.387457\n",
            "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 0.313094\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.309616\n",
            "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 0.179131\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.331292\n",
            "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 0.182784\n",
            "\n",
            "Test set: Average loss: 0.0728, Accuracy: 9765/10000 (98%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.197990\n",
            "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 0.206875\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.245112\n",
            "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 0.195434\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.108387\n",
            "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 0.161800\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.156402\n",
            "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 0.234497\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.147884\n",
            "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 0.229116\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.156866\n",
            "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 0.208789\n",
            "\n",
            "Test set: Average loss: 0.0635, Accuracy: 9800/10000 (98%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.117619\n",
            "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 0.195879\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.098306\n",
            "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 0.231304\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.146361\n",
            "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 0.188554\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.134877\n",
            "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 0.210832\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.181129\n",
            "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 0.199305\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.158304\n",
            "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 0.118080\n",
            "\n",
            "Test set: Average loss: 0.0580, Accuracy: 9802/10000 (98%)\n",
            "\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.162137\n",
            "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 0.306139\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.122104\n",
            "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 0.204441\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.118958\n",
            "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 0.242037\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.242256\n",
            "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 0.340713\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.420015\n",
            "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 0.175913\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.161608\n",
            "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 0.129939\n",
            "\n",
            "Test set: Average loss: 0.0493, Accuracy: 9839/10000 (98%)\n",
            "\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.099169\n",
            "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 0.180521\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.400978\n",
            "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 0.122122\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.208662\n",
            "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 0.132265\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.164191\n",
            "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 0.125669\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.060372\n",
            "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 0.120258\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.211912\n",
            "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 0.078141\n",
            "\n",
            "Test set: Average loss: 0.0470, Accuracy: 9847/10000 (98%)\n",
            "\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.061042\n",
            "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 0.183856\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.232954\n",
            "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 0.110778\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.102881\n",
            "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 0.168999\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.319249\n",
            "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 0.141541\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.173722\n",
            "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 0.146810\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.285644\n",
            "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 0.331846\n",
            "\n",
            "Test set: Average loss: 0.0436, Accuracy: 9865/10000 (99%)\n",
            "\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.082669\n",
            "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 0.234564\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.066694\n",
            "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 0.142015\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.099559\n",
            "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 0.060729\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.146156\n",
            "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 0.160140\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.106525\n",
            "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 0.272546\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.104043\n",
            "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 0.102287\n",
            "\n",
            "Test set: Average loss: 0.0442, Accuracy: 9861/10000 (99%)\n",
            "\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.133541\n",
            "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 0.076060\n",
            "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 0.086825\n",
            "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 0.083895\n",
            "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 0.044585\n",
            "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 0.129487\n",
            "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 0.098626\n",
            "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 0.134123\n",
            "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 0.196207\n",
            "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 0.194631\n",
            "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 0.248708\n",
            "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 0.223986\n",
            "\n",
            "Test set: Average loss: 0.0433, Accuracy: 9859/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Visualizing Predictions\n",
        "\n",
        "We can visualize the model's predictions on individual test images to assess its performance qualitatively."
      ],
      "metadata": {
        "id": "NiPxEN9W6LYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_single_image(index):\n",
        "    model.eval()\n",
        "    data, target = test_data[index]\n",
        "    data = data.unsqueeze(0).to(device)\n",
        "\n",
        "    output = model(data)\n",
        "    prediction = output.argmax(dim=1, keepdim=True).item()\n",
        "    print(f'Prediction: {prediction}')\n",
        "\n",
        "    image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "    plt.imshow(image, cmap='gray')\n",
        "    plt.title(f'Predicted: {prediction}')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "predict_single_image(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "sNrAA64-6LzF",
        "outputId": "d66ffeca-1187-45aa-b4ae-742e7200ab84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "We successfully built and trained a Convolutional Neural Network (CNN) to classify handwritten digits from the MNIST dataset. The model achieved an accuracy of approximately 99%, demonstrating the effectiveness of CNNs in image classification tasks."
      ],
      "metadata": {
        "id": "FbqbRQc06Oz7"
      }
    }
  ]
}