{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1Pw5AIpt5gFC"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = True,\n",
        "    transform = ToTensor(),\n",
        "    download = True,\n",
        ")\n",
        "test_data = datasets.MNIST(\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")"
      ],
      "metadata": {
        "id": "x2DRVmar6USq"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNAlQo-68aE5",
        "outputId": "05054c82-5739-435a-a987-e46fe723ea00"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8hrpWU08c99",
        "outputId": "d09777ea-061a-4797-ceac-fea8961f46be"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBJGmplh8gN4",
        "outputId": "f88074d2-e40d-48e0-b3e8-c2e08bf9be17"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG_Ji9lG8ssX",
        "outputId": "9fc71a83-56cf-4b3f-d259-1a0231f46879"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV-vjGvO8vyj",
        "outputId": "39be75f4-04a6-44a2-dc89-c5999ef0fb91"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzTenB04805i",
        "outputId": "e82b24cb-c928-4dd7-a1c9-6d8134dbffa9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4,  ..., 5, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "loaders = {\n",
        "    'train' : DataLoader(train_data,\n",
        "                        batch_size=100,\n",
        "                        shuffle=True,\n",
        "                        num_workers=1),\n",
        "\n",
        "    'test'  : DataLoader(test_data,\n",
        "                        batch_size=100,\n",
        "                        shuffle=True,\n",
        "                        num_workers=1),\n",
        "}"
      ],
      "metadata": {
        "id": "hmly4-Kl84-X"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loaders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJKRPz7g9a5J",
        "outputId": "6bbb824f-29ed-47d8-b08d-4801dab17049"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7e8e79c7cc40>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x7e8e79c7d7b0>}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    x = x.view(-1, 320)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return F.softmax(x)"
      ],
      "metadata": {
        "id": "Jz2THQFQ9dr1"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = CNN().to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad\n",
        "    output = model(data)\n",
        "    loss = loss_fn(output, target)\n",
        "    loss.backward()\n",
        "    if batch_idx % 50 == 0:\n",
        "      print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
        "\n",
        "def test():\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, target in loaders['test']:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += loss_fn(output, target).item()\n",
        "      pred = output.data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
        "\n",
        "  test_loss /= len(loaders['test'].dataset)\n",
        "  print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%)')"
      ],
      "metadata": {
        "id": "PSYqUWPxcczz"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 11):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76Ar_wvag_xv",
        "outputId": "828c23df-cae9-4cb1-adaa-adb489a1831a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-31-aa376e6c1fe2>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.303901\n",
            "Train Epoch: 1 [5000/60000 (8%)]\tLoss: 2.301859\n",
            "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 2.302455\n",
            "Train Epoch: 1 [15000/60000 (25%)]\tLoss: 2.302359\n",
            "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 2.301539\n",
            "Train Epoch: 1 [25000/60000 (42%)]\tLoss: 2.301733\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.300736\n",
            "Train Epoch: 1 [35000/60000 (58%)]\tLoss: 2.301877\n",
            "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 2.301849\n",
            "Train Epoch: 1 [45000/60000 (75%)]\tLoss: 2.302227\n",
            "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 2.301837\n",
            "Train Epoch: 1 [55000/60000 (92%)]\tLoss: 2.301815\n",
            "\n",
            "Test set: Average loss: 0.0230, Accuracy: 1060/10000 (11%)\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 2.302300\n",
            "Train Epoch: 2 [5000/60000 (8%)]\tLoss: 2.301570\n",
            "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 2.303454\n",
            "Train Epoch: 2 [15000/60000 (25%)]\tLoss: 2.302107\n",
            "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 2.302207\n",
            "Train Epoch: 2 [25000/60000 (42%)]\tLoss: 2.301510\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 2.302689\n",
            "Train Epoch: 2 [35000/60000 (58%)]\tLoss: 2.301406\n",
            "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 2.302441\n",
            "Train Epoch: 2 [45000/60000 (75%)]\tLoss: 2.303288\n",
            "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 2.303210\n",
            "Train Epoch: 2 [55000/60000 (92%)]\tLoss: 2.303640\n",
            "\n",
            "Test set: Average loss: 0.0230, Accuracy: 1060/10000 (11%)\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 2.302777\n",
            "Train Epoch: 3 [5000/60000 (8%)]\tLoss: 2.302019\n",
            "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 2.302519\n",
            "Train Epoch: 3 [15000/60000 (25%)]\tLoss: 2.302323\n",
            "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 2.302191\n",
            "Train Epoch: 3 [25000/60000 (42%)]\tLoss: 2.303010\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 2.302434\n",
            "Train Epoch: 3 [35000/60000 (58%)]\tLoss: 2.303143\n",
            "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 2.301677\n",
            "Train Epoch: 3 [45000/60000 (75%)]\tLoss: 2.301048\n",
            "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 2.302890\n",
            "Train Epoch: 3 [55000/60000 (92%)]\tLoss: 2.302938\n",
            "\n",
            "Test set: Average loss: 0.0230, Accuracy: 1060/10000 (11%)\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 2.302806\n",
            "Train Epoch: 4 [5000/60000 (8%)]\tLoss: 2.302850\n",
            "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 2.302140\n",
            "Train Epoch: 4 [15000/60000 (25%)]\tLoss: 2.303345\n",
            "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 2.302628\n",
            "Train Epoch: 4 [25000/60000 (42%)]\tLoss: 2.300553\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 2.301408\n",
            "Train Epoch: 4 [35000/60000 (58%)]\tLoss: 2.301813\n",
            "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 2.302216\n",
            "Train Epoch: 4 [45000/60000 (75%)]\tLoss: 2.302485\n",
            "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 2.302786\n",
            "Train Epoch: 4 [55000/60000 (92%)]\tLoss: 2.302567\n",
            "\n",
            "Test set: Average loss: 0.0230, Accuracy: 1060/10000 (11%)\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 2.303252\n",
            "Train Epoch: 5 [5000/60000 (8%)]\tLoss: 2.302536\n",
            "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 2.303000\n",
            "Train Epoch: 5 [15000/60000 (25%)]\tLoss: 2.301885\n",
            "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 2.303771\n",
            "Train Epoch: 5 [25000/60000 (42%)]\tLoss: 2.302665\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 2.302422\n",
            "Train Epoch: 5 [35000/60000 (58%)]\tLoss: 2.302118\n",
            "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 2.303314\n",
            "Train Epoch: 5 [45000/60000 (75%)]\tLoss: 2.302734\n",
            "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 2.303083\n",
            "Train Epoch: 5 [55000/60000 (92%)]\tLoss: 2.302202\n",
            "\n",
            "Test set: Average loss: 0.0230, Accuracy: 1060/10000 (11%)\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 2.302604\n",
            "Train Epoch: 6 [5000/60000 (8%)]\tLoss: 2.301899\n",
            "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 2.302699\n",
            "Train Epoch: 6 [15000/60000 (25%)]\tLoss: 2.301152\n",
            "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 2.301982\n",
            "Train Epoch: 6 [25000/60000 (42%)]\tLoss: 2.302253\n",
            "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 2.301126\n",
            "Train Epoch: 6 [35000/60000 (58%)]\tLoss: 2.301893\n",
            "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 2.302398\n",
            "Train Epoch: 6 [45000/60000 (75%)]\tLoss: 2.303139\n",
            "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 2.300933\n",
            "Train Epoch: 6 [55000/60000 (92%)]\tLoss: 2.301955\n",
            "\n",
            "Test set: Average loss: 0.0230, Accuracy: 1060/10000 (11%)\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 2.301862\n",
            "Train Epoch: 7 [5000/60000 (8%)]\tLoss: 2.301920\n",
            "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 2.301452\n",
            "Train Epoch: 7 [15000/60000 (25%)]\tLoss: 2.301264\n",
            "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 2.303313\n",
            "Train Epoch: 7 [25000/60000 (42%)]\tLoss: 2.302314\n",
            "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 2.301875\n",
            "Train Epoch: 7 [35000/60000 (58%)]\tLoss: 2.302395\n",
            "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 2.301515\n",
            "Train Epoch: 7 [45000/60000 (75%)]\tLoss: 2.302140\n",
            "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 2.301521\n",
            "Train Epoch: 7 [55000/60000 (92%)]\tLoss: 2.302469\n",
            "\n",
            "Test set: Average loss: 0.0230, Accuracy: 1060/10000 (11%)\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 2.301858\n",
            "Train Epoch: 8 [5000/60000 (8%)]\tLoss: 2.302112\n",
            "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 2.303017\n",
            "Train Epoch: 8 [15000/60000 (25%)]\tLoss: 2.301934\n",
            "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 2.302051\n",
            "Train Epoch: 8 [25000/60000 (42%)]\tLoss: 2.302327\n",
            "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 2.302428\n",
            "Train Epoch: 8 [35000/60000 (58%)]\tLoss: 2.302578\n",
            "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 2.303401\n",
            "Train Epoch: 8 [45000/60000 (75%)]\tLoss: 2.301997\n",
            "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 2.301782\n",
            "Train Epoch: 8 [55000/60000 (92%)]\tLoss: 2.301925\n",
            "\n",
            "Test set: Average loss: 0.0230, Accuracy: 1060/10000 (11%)\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 2.303158\n",
            "Train Epoch: 9 [5000/60000 (8%)]\tLoss: 2.301319\n",
            "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 2.303365\n",
            "Train Epoch: 9 [15000/60000 (25%)]\tLoss: 2.303394\n",
            "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 2.302284\n",
            "Train Epoch: 9 [25000/60000 (42%)]\tLoss: 2.302438\n",
            "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 2.302256\n",
            "Train Epoch: 9 [35000/60000 (58%)]\tLoss: 2.301870\n",
            "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 2.303300\n",
            "Train Epoch: 9 [45000/60000 (75%)]\tLoss: 2.302064\n",
            "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 2.301252\n",
            "Train Epoch: 9 [55000/60000 (92%)]\tLoss: 2.303530\n",
            "\n",
            "Test set: Average loss: 0.0230, Accuracy: 1060/10000 (11%)\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 2.302993\n",
            "Train Epoch: 10 [5000/60000 (8%)]\tLoss: 2.301656\n",
            "Train Epoch: 10 [10000/60000 (17%)]\tLoss: 2.301480\n",
            "Train Epoch: 10 [15000/60000 (25%)]\tLoss: 2.302331\n",
            "Train Epoch: 10 [20000/60000 (33%)]\tLoss: 2.301670\n",
            "Train Epoch: 10 [25000/60000 (42%)]\tLoss: 2.300914\n",
            "Train Epoch: 10 [30000/60000 (50%)]\tLoss: 2.303035\n",
            "Train Epoch: 10 [35000/60000 (58%)]\tLoss: 2.302396\n",
            "Train Epoch: 10 [40000/60000 (67%)]\tLoss: 2.302444\n",
            "Train Epoch: 10 [45000/60000 (75%)]\tLoss: 2.302104\n",
            "Train Epoch: 10 [50000/60000 (83%)]\tLoss: 2.303844\n",
            "Train Epoch: 10 [55000/60000 (92%)]\tLoss: 2.302212\n",
            "\n",
            "Test set: Average loss: 0.0230, Accuracy: 1060/10000 (11%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval()\n",
        "\n",
        "data, target = test_data[3]\n",
        "\n",
        "data = data.unsqueeze(0).to(device)\n",
        "\n",
        "output = model(data)\n",
        "\n",
        "prediction = output.argmax(dim=1, keepdim=True).item()\n",
        "\n",
        "print(f'Prediction: {prediction}')\n",
        "\n",
        "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "Ni0VqRBuipbE",
        "outputId": "86b90260-c833-478b-add2-77d46f2f3969"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-aa376e6c1fe2>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}