{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine-Tuning ResNet50 for Cats and Dogs Classification**\n",
        "**Author:** Khai Ta  \n",
        "**Date:** November 2024  \n",
        "\n",
        "In this project, we fine-tune the ResNet50 model to classify images of cats and dogs, modifying the final layer to make it specific for binary classification.\n"
      ],
      "metadata": {
        "id": "G-DYwNSVOSnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Import Libraries"
      ],
      "metadata": {
        "id": "AnbSpVI5RBiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import zipfile\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "G_GiCKSnRCIy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Load and Extract Dataset\n",
        "We will download the dataset of cat and dog images, which is provided in a zipped format. After downloading, we will extract the contents so that we can access the training and validation images."
      ],
      "metadata": {
        "id": "YuY0mqirPi_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djdxyqPMU-bn",
        "outputId": "2af2e61b-a10f-4ba1-fe2f-ad9e041f8065"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-01 16:24:24--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.8.207, 142.251.170.207, 173.194.174.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.8.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  22.5MB/s    in 2.9s    \n",
            "\n",
            "2024-11-01 16:24:28 (22.5 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Prepare the Data\n",
        "Now, we will preprocess the images for our model. This involves loading images from the respective directories, resizing them to a uniform size, and converting them into numpy arrays suitable for input into the model. We will also create labels for our images, where 1 represents cats and 0 represents dogs."
      ],
      "metadata": {
        "id": "M1VOK46vVdxM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUMBER_OF_TRAINING_EXAMPLES = 1000\n",
        "NUMBER_OF_VALIDATION_EXAMPLES = 200\n",
        "IMAGE_SIZE = (150, 150)\n",
        "\n",
        "def load_data(directory, num_examples):\n",
        "    x_data = []\n",
        "    y_data = []\n",
        "\n",
        "    cats_dir = os.path.join(directory, \"cats\")\n",
        "    dogs_dir = os.path.join(directory, \"dogs\")\n",
        "\n",
        "    for i in range(num_examples):\n",
        "        if i % 2 == 0:\n",
        "            img_path = os.path.join(cats_dir, os.listdir(cats_dir)[i])\n",
        "            label = 1\n",
        "        else:\n",
        "            img_path = os.path.join(dogs_dir, os.listdir(dogs_dir)[i])\n",
        "            label = 0\n",
        "\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img_resized = img.resize(IMAGE_SIZE)\n",
        "\n",
        "        x_data.append(np.array(img_resized))\n",
        "        y_data.append(label)\n",
        "\n",
        "    return np.array(x_data), np.array(y_data)\n",
        "\n",
        "x_train, y_train = load_data(train_dir, NUMBER_OF_TRAINING_EXAMPLES)\n",
        "x_val, y_val = load_data(validation_dir, NUMBER_OF_VALIDATION_EXAMPLES)"
      ],
      "metadata": {
        "id": "ZIzsVpWzVs_h"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Load Pre-trained ResNet Model\n",
        "We will then load ResNet50 with pre-trained ImageNet weights and remove the top layer to modify the model for binary classification."
      ],
      "metadata": {
        "id": "enCipZk3Vqs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained_model = tf.keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    input_shape=(150, 150, 3),\n",
        "    pooling='avg',\n",
        "    weights='imagenet'\n",
        ")"
      ],
      "metadata": {
        "id": "BnKy25QJZ_tG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Add a Simple Output Layer\n",
        "Next, we will create a new model by stacking a global average pooling layer on top of the pre-trained ResNet50 model, followed by a dense layer with a sigmoid activation function. This configuration will allow us to classify the input images into one of two categories: cat or dog."
      ],
      "metadata": {
        "id": "5VDbNDlVaRoP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    pretrained_model,\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')  # Sigmoid for binary output (cat or dog)\n",
        "])"
      ],
      "metadata": {
        "id": "9OgtSymcadhk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Compile the Model\n",
        "For binary classification, we will compile our model using binary crossentropy as the loss function and the Adam optimizer."
      ],
      "metadata": {
        "id": "7djSDa3iaiDM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "I599Iqwza3q5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Train the Model\n",
        "With the model compiled, we can now train it using the prepared training and validation data for 5 epochs."
      ],
      "metadata": {
        "id": "a2bSn2v9a7ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=5, validation_data=(x_val, y_val), batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFvdQTm2b4xD",
        "outputId": "da449ca3-d2a9-4ba8-ad4b-265920302e9e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 12s/step - accuracy: 0.7909 - loss: 0.5450 - val_accuracy: 0.5000 - val_loss: 261290.1562\n",
            "Epoch 2/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m429s\u001b[0m 12s/step - accuracy: 0.8370 - loss: 0.4404 - val_accuracy: 0.5000 - val_loss: 5339.1064\n",
            "Epoch 3/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m391s\u001b[0m 12s/step - accuracy: 0.8224 - loss: 0.3896 - val_accuracy: 0.7900 - val_loss: 4.6878\n",
            "Epoch 4/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m371s\u001b[0m 12s/step - accuracy: 0.9260 - loss: 0.2162 - val_accuracy: 0.6450 - val_loss: 2.3802\n",
            "Epoch 5/5\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m375s\u001b[0m 11s/step - accuracy: 0.9739 - loss: 0.0850 - val_accuracy: 0.8550 - val_loss: 0.4753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8. Evaluate the Model\n",
        "After training, we can evaluate our model's performance on the validation set to ensure that it generalizes well to unseen data, providing us with the final accuracy."
      ],
      "metadata": {
        "id": "u29NPDnvgrtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_val, y_val)\n",
        "print(f\"Validation Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjdkIIUigvsk",
        "outputId": "f7058694-ab74-45c8-b5ac-1c7e138f5b76"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 2s/step - accuracy: 0.8796 - loss: 0.4020\n",
            "Validation Accuracy: 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "We successfully fine-tuned a ResNet50 model to classify cats and dogs, achieving good accuracy by leveraging pre-trained weights. This method of transfer learning enables efficient training and high performance with minimal modifications."
      ],
      "metadata": {
        "id": "pZnYhs44jmY2"
      }
    }
  ]
}